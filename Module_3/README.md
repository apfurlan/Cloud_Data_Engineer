# Massive Data Processing

[![Status](https://img.shields.io/badge/status-active-success.svg)]()
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE)


&nbsp;

This module was dedicated to studying the processing of massive data by using [Pyspark](https://spark.apache.org/docs/latest/api/python/). The topics covered here will be :

&nbsp;

1. Manipulating data with Spark: Part 1.
2. Manipulating data with Spark: Part 2.
3. Spark SQL.
4. Optimizing Spark Aplications .

&nbsp;

Here you will see : 
 <img align="center" alt="Python" height="50" width="50" src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg"> <img align="center" alt="C" height="50" width="50" src="https://www.instana.com/media/01_INSTANA_IconSet_ApacheSpark.svg"> <img align="center" alt="C" height="50" width="50" src="https://symbols.getvecta.com/stencil_28/61_sql-database-generic.90b41636a8.svg">

---

### **Notes:**
- The exercises were developed in Google Colab. If you have Pyspark installed in your PC, please disregard the first cell of the .ipynb files
and path used a long the exercise.
- Due to the size of the Dataset, I didnÂ´t upload the file. The dataset used for this exercise can be accessed on the link : https://datasets.imdbws.com/